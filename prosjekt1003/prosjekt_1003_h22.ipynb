{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a9dfee-aee4-4a4d-992a-d2c0250a634a",
   "metadata": {},
   "source": [
    "# Tellende prosjekt i ISTx1003 - høst 2022<a name=\"top\"></a>\n",
    "\n",
    "I prosjektdelen av ISTx1003 Statistikk, Statistisk læring og data science, har vi fokus på tre hovedtemaer: \n",
    "*regresjon, klassifikasjon og klyngeanalyse*.\n",
    "\n",
    "* Dette er oppgaveteksten til den tellende prosjektoppgaven, der besvarelsen teller 30% av karakteren i emnet.\n",
    "* Det skal være 4-6 studenter på hver gruppe, og alle studenter må være oppmeldt i den samme emnekoden (det vil si: én av ISTA1003, ISTG1003, ISTT1003).  **Det er opprettet gruppesett under \"Prosjektgrupper: påmelding\" på Blackboard**, der dere melder dere på innen **31. oktober 2022**. \n",
    "* Informasjon om prosjektmodulen finnes i Blackboard, sammen med alt kursmateriellet.\n",
    "* Oppgaven skal utføres i Python, ved hjelp av Jupyter-notatbok-versjonen av denne filen som du nå leser. Notatboken er lastet opp på Jupyterhuben, men kan også finnes på Blackboard under fanen for 'ISTx1003'.\n",
    "* Det er meningen at dere skal kjøre notatboken på Jupyterhuben vår https://s.ntnu.no/isthub, eller på deres egen installasjon.\n",
    "* De ulike oppgavene (1, 2, 3) er vektet ulikt (50%, 30% og 20%). Antall spørsmål i hver oppgave og deloppgave varierer, men hvert spørsmål innad i hver oppgave (1, 2 og 3) teller like mye. Karakteren settes med prosentvurderingsmetoden hvor poeng blir konvertert i en prosentandel (ikke-heltall prosent blir avrundet): https://innsida.ntnu.no/wiki/-/wiki/Norsk/Prosentvurderingsmetoden\n",
    "* Prosjektet leveres i Inspera.\n",
    "\n",
    "Dere skal skrive svar på spørsmålene i dette Word-dokumentet: https://www.math.ntnu.no/emner/IST100x/ISTx1003/h2022/svarark.docx. Når dere skal levere, gjør dere filen om til en pdf (Save as/Lagre som, og så velg pdf). Dere skal også levere Jupyter notatboka dere har brukt og redigert for å få svart på oppgavene, i pdf-format. Den kan lastes ned og lagres som pdf under \"File\" -> \"Save and Export Notebook As...\" og så velger dere pdf, eventuelt HTML og så lagrer HTML-siden som en.\n",
    "(Det er to grunner til å bruke denne malen: Det letter samskriving og det letter karaktersetting.)\n",
    "\n",
    "**Dere skal altså laste opp *to* filer:**\n",
    "* én pdf-fil med svar, og\n",
    "* én pdf-fil som er en Jupyter notatbok til Inspera.\n",
    "\n",
    "**Frist for innlevering av prosjektet til Inspera er mandag 21. november 2020, klokka 12:00.**\n",
    "\n",
    "Kontakt eksamenskontoret ved problemer. Det kan ikke gis utsettelse på innleveringsfristen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5157c12-6eb5-4ec3-9ccc-8c30b8f6e91f",
   "metadata": {},
   "source": [
    "## Innholdsfortegnelse\n",
    "* [Oppgave 1: Regresjon](#oppgave1)\n",
    "* [Oppgave 2: Klassifikasjon](#oppgave2)\n",
    "* [Oppgave 3: Klyngeanalyse](#oppgave3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac3ede6-c1e5-4a2c-a07b-afe77b8c7155",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Oppgave 1 - Lineær regresjon (50%)<a name=\"oppgave1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ad3b5c-a567-474e-8990-98472c4a090f",
   "metadata": {
    "tags": []
   },
   "source": [
    "*Oppgave 1 inneholder 3 deler med oppgaver, og alle 29 spørsmål (Q1a.1), Q1a.2) etc.) teller likt. Oppgave 1 teller totalt 50 % av prosjektet.*\n",
    "\n",
    "**Oppgaven inneholder følgende elementer:**\n",
    "\n",
    "* Laste inn og utforske et datasett\n",
    "* Tilpasse en enkel lineær regresjonsmodell og diskutere denne\n",
    "* Tilpasse en multippel lineær regresjonsmodell og diskutere denne\n",
    "\n",
    "## Innholdsfortegnelse\n",
    "* [Introduksjon](#intro)\n",
    "* [Rådata](#radata)\n",
    "* [Oppgave 1a) Dataoppsett og klargjøring av data](#oppgave1a)\n",
    "* [Oppgave 1b) Enkel regresjon](#oppgave1b)\n",
    "* [Oppgave 1c) Multippel lineær regresjon](#oppgave1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5182c2-c0f2-4eef-9e09-4df5b0587751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importere pakker og funksjoner vi trenger i oppgave 1\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# for å fjerne unødvendige feilmeldinger om at noen pakker i fremtiden vil se annerledes ut\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc958e6-3efb-41c4-b10f-d3f66caacd25",
   "metadata": {},
   "source": [
    "### Introduksjon<a name=\"intro\"></a>\n",
    "\n",
    "Statens Vegvesen (SVV) har en ambisjon om smartere vedlikehold av veinettet og bygging av trygge veier, med færre enn 350 døde eller hardt skadde i trafikkulykker i året innen 2030. Dette følger av Nullvisjonen - SVVs langtidsmål om ingen dødsfall og hardt skadde. For å oppnå dette har SVV investert over en milliard kroner i forskning og teknologi for å forstå forfall av veinettet.\n",
    "\n",
    "For øyeblikket bruker SSV en reaktiv strategi når det kommer til risikovurdering for veinettet. Altså finner vedlikhold sted etter at veien allerede har forfalt. Stengte veier kan ha store miljømessige og økonomiske konsekvenser, blant annet, og dermed er reaktive vedlikeholdsstrategier ineffektive. Slike strategier passer bedre til situasjoner der forfall ikke har store konsekvenser. På grunn av nullvisjonen går SVV derfor over mot preventive (vedlikehold utføres periodisk enten det er nødvendig eller ikke) og prediktive (man måler tilstanden til veien for å beregne når vedlikehold blir nødvendig) vedlikeholdsstrategier.\n",
    "\n",
    "Forståelse av hvordan veier forfaller vil kunne være hjelpsomt når det kommer til å planlegge optimalt vedlikeholdsarbeid og hvor ofte vedlikehold skal utføres for å minimere stenging av veier. Altså er målet å trekke slutninger om kvaliteten på et stykke vei basert på kjente (eller ukjente) påvirkningsfaktorer, og identifisere veistrekninger som forfaller raskere. \n",
    "\n",
    "I denne oppgaven skal vi utføre deskriptive analyser og tilpasse statistiske modeller innenfor rammeverket lineære regresjon, for å indentifisere veiområdene med størst behov for vedlikehold. Modellene skal tilpasses data fra en elleveårs periode (2010-2020), innsamlet fra den omtrent $66.7$ kilometers lange veistrekningen på E14 som går fra Stjørdal til svenskegrensa. Området er markert i figuren under."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b050f5a-502f-4519-883a-88d96306cbf5",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"https://www.math.ntnu.no/emner/IST100x/ISTx1003/h2022/map_of_norway.png\" width=\"300\">\n",
    "  <figcaption>E14 ligger i det røde området.</figcaption>\n",
    "</figure>\n",
    "<figure>\n",
    "  <img src=\"https://www.math.ntnu.no/emner/IST100x/ISTx1003/h2022/e14.png\" width=\"600\">\n",
    "  <figcaption>Skjermdump av E14 fra Google maps.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0fc2b7-fef1-4fbf-ac7b-f85778f00bbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Rådata<a name=\"radata\"></a>\n",
    "\n",
    "Datainnsamlingen ble utført på E14 fra Stjørdal til svenskegrensa, en strekning som er ca. \n",
    "$67.8$ kilometer lang. Vi har elleve år med årlige veioverflatemålinger på veistykker som er ca. $20$ meter lange. Vi har $3355$ slike $20$-meters veistykker. Datasettet er omfattende og har informasjon om nye veilegginger (f. eks. asfalttype), spordybde, tverrfall, ruhet, geometri og diverse strukturelle målinger som beskriver tilstanden til veien. Målingene ble gjort med ViaPPs - et målesystem utviklet av ViaTech i samarbeid med SVV. ViaPPS-systemet festes til et kjøretøy, og måler veioverflaten og omgivelsene med bruk av LiDAR. Målingene, som f.eks. spordybde, er indikatorer på veikvalitet. Desto dypere sporing, desto mindre trafikksikker er veien, siden kjørekvaliteten og stabiliteten senkes. Dermed bruker vi her spordybde som et mål på veiytelse og veiens forventede levetid.\n",
    "\n",
    "I tillegg til veioverflatemålinger, har vi også data om gjennomsnittlig daglig trafikkdata per $1000$ meter (dvs. trafikkintensitet, her forkortet med AADT, som står for average annual daily traffic), veidekketype (dvs. asfalttype), veibredde, grøftedybde. Vi regner AADT som høy dersom den er over $5000$, og som lav dersom den er under $5000$. SVV antar at nylagte veistykker har forventet levetid på 20-30 år, og anbefaler at vedlikeholdsarbeid utføres dersom spordybden er over $25$ mm i områder med lav AADT eller over $20$ mm i områder med høy AADT.\n",
    "\n",
    "Det er flere faktorer som påvirker årlig spordybde, f. eks. trafikktrykket (antall og størrelse på kjøretøy), miljøfaktorer (som vær og temperatur) og veiens iboende egenskaper (som materiale og byggekvalitet). Når en ny vei legges akselereres sporing på grunn av komprimering fra trafikk. Deretter stabiliseres sporingen en stund, før den igjen øker raskt, og da blir sporingen synlig med det blotte øye. *I denne oppgaven definerer vi sporing som den årlige endringen i en spordybdemåling.*\n",
    "\n",
    "<figure>\n",
    "  <img src=\"https://www.math.ntnu.no/emner/IST100x/ISTx1003/h2022/sporing.jpg\" width=\"300\">\n",
    "  <figcaption>Disse \"gropene\" i veien er sporing.</figcaption>\n",
    "</figure>\n",
    "\n",
    "Mesteparten av dataene vi bruker i oppgaven kommer fra SVVs offentlig tilgjengelige Nasjonal vegdatabank (NVDB), se https://vegkart.atlas.vegvesen.no/. Selve sporingsdybden er hentet fra Rosita-databasen (disse dataene ligger ikke åpent for alle, men vi får bruke dem i dette prosjektet)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e682dc7-bdb2-43a1-af11-eb07a6f17c09",
   "metadata": {},
   "source": [
    "### Oppgave 1a) Dataoppsett og klargjøring av data<a name=\"oppgave1a\"></a>\n",
    "\n",
    "*Oppgave 1a) inneholder 6 spørsmål som du skal svare på.*\n",
    "\n",
    "Før vi begynner selve analysen skal vi bli kjent med datasettet. Denne deloppgaven krever ingen koding.\n",
    "\n",
    "Når vi får dataene, kommer de som en stor fil med masse informasjon. Vi har allerede fikset datasettet så det er klart for regresjonsanalysene dere skal gjøre i denne oppgaven, og forklart hvordan i denne filen: https://www.math.ntnu.no/emner/IST100x/ISTx1003/h2022/fikse_data.html (merk: dere skal ikke kjøre kode selv her). Svar på noen spørsmålene i deloppgave 1a) finner dere ved å lese gjennom filen, resten av svarene finner dere i denne notatboka.\n",
    "\n",
    "Herfra antar vi at dere har lest filen som viser hvordan dataene er hentet ut fra det store, originale datasettet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0ff052-990b-463a-9525-ff37ea1426c2",
   "metadata": {},
   "source": [
    "Responsvariablen er sporing (årlig endring i spordybde, målt i millimeter) per ti tusen biler. Vi ser på endring i spordybde fordi det sier noe om forfallsprosessen fra et datadrevet perspektiv, og per ti tusen biler fordi vi vil kunne bruke kunnskapen om E14 til å forutsi hvordan veiene burde vedlikeholdes steder med mer/mindre trafikk også. I tillegg forventer vi ingen økning i spordybden på veier der ingen biler kjører.\n",
    "Hvis endringen i spordybde er svært negativ (altså at spordybden plutselig har blitt mye mindre enn året før) kan vi gå ut i fra at det er fordi en ny vei har blitt lagt.\n",
    "\n",
    "Forklaringsvariablene er: \n",
    "\n",
    "1) asfalttype (svakere binding i asfalt, f.eks. grus, gir raskere sporing), \n",
    "2) veibredde målt i meter (tynnere veier gir raskere sporing), \n",
    "3) spordybde målt i millimeter fra det forrige året."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753bc529-0141-44be-b807-ccaf453a7b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laste inn dataene (vi kaller den 'df', for 'data frame')\n",
    "df = pd.read_csv('https://www.math.ntnu.no/emner/IST100x/ISTx1003/h2022/sporing_data.csv', sep = \",\")\n",
    "# printe første og siste radene\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f7165-2671-423d-8765-5cf4ae9f7fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ser litt ekstra på asfalt-dataene\n",
    "df['asfalt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e70584f-8b45-4c55-91fe-80f278ab7b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(3, 2, figsize = (12, 12))\n",
    "\n",
    "axis[0, 0].scatter(df['posisjon'], df['sporing'], s = 2)\n",
    "axis[0, 0].set_xlabel(\"Posisjon\"); axis[0, 0].set_ylabel(\"Sporing\")\n",
    "\n",
    "axis[0, 1].scatter(df['posisjon'], df['sporing_trafikk'], s = 2)\n",
    "axis[0, 1].set_xlabel(\"Posisjon\"); axis[0, 1].set_ylabel(\"Sporing/AADT\")\n",
    "\n",
    "axis[1, 0].scatter(df['posisjon'], df['spordybde'], s = 2)\n",
    "axis[1, 0].set_xlabel(\"Posisjon\"); axis[1, 0].set_ylabel(\"Spordybde\")\n",
    "  \n",
    "axis[1, 1].scatter(df['posisjon'], df['veibredde'], s = 2)\n",
    "axis[1, 1].set_xlabel(\"Posisjon\"); axis[1, 1].set_ylabel(\"Veibredde\")\n",
    "\n",
    "axis[2, 0].scatter(df['posisjon'], df['asfalt'], s = 2)\n",
    "axis[2, 0].set_xlabel(\"Posisjon\"); axis[2, 0].set_ylabel(\"Asfalt\")\n",
    "\n",
    "axis[-1, -1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78126502-f86d-4a93-8b2e-42a65d0ea089",
   "metadata": {},
   "source": [
    "Vi ser at det er mange steder spordybden overstiger grensa på Vegvesenet har satt for når de må fikse veien. \n",
    "Grensa er $25$ mm for vei med lav trafikkintensitet og $20$ mm for vei med høy trafikkintensitet.\n",
    "Før vi går i gang med oppgavene vil vi se om de stedene som hadde spordybde på mer enn $25$ mm har negativ sporing året etter. Vi har ikke lagret trafikkintensiteten i dataene, så vi velger å se på områdene med mer enn $25$ mm, da det er en vei som må fikses uansett trafikkintensitet.\n",
    "\n",
    "Vi plotter et frekvensplott med sporingen per ti tusen biler til de veistrekningene som i 2019 hadde mer enn $25$ mm sporing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a919abb-08a4-440f-8264-79cd9c633a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[df['spordybde'] > 25]['sporing'], bins = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2725aa6d-5098-4e11-b0f7-2ebb2080564d",
   "metadata": {},
   "source": [
    "Noen av de 20 meter lange veistrekningene har fått en negativ sporing, men de fleste har en positiv verdi for sporing, og veien har ikke blitt fikset siden 2019 selv om spordybden da overskred SVVs grense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e05e5-9547-483a-9c02-0dcb4df2c2c0",
   "metadata": {},
   "source": [
    "**Q1a.1)** Hvor mange observasjoner har vi i datasettet? Matcher det med lengden på hver del av veien og den totale veilengden?\n",
    "\n",
    "**Q1a.2)** Hva tror du en negativ verdi av `sporing` betyr i praksis? Hvordan tolker vi betydningen av `sporing_trafikk`?\n",
    "\n",
    "**Q1a.3)** Vi manglet originalt 17 av 3355 målinger av veibredden. Hvordan løste vi det?\n",
    "\n",
    "**Q1a.4)** Hva er det fulle navnet på asfalttypen vi har mest av? (skjelettasfalt, asfaltbetong eller asfaltgrusbetong)\n",
    "\n",
    "**Q1a.5)** Hvorfor tror du veibredden er mye større for lave verdier av avstand?\n",
    "\n",
    "**Q1a.6)** SVV vil at nye veier skal holde i 20-30 år. Basert på dataene fra 2020, er det realistisk? Hvorfor/hvorfor ikke? Veien skal repareres når spordybden blir for stor. Blir veien reparert ofte nok? Gi en kort begrunnelse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae461ca9-cea0-4a30-982c-ecb0f5092a66",
   "metadata": {},
   "source": [
    "### Oppgave 1b) Enkel lineær regresjon<a name=\"oppgave1b\"></a>\n",
    "\n",
    "*Oppgave 1b) inneholder 12 spørsmål som du skal svare på.*\n",
    "\n",
    "Nå skal vi se på endring i sporingsdybde, og undersøke om spordybden fra året før er en god forklaringsvariabel for dette. Under ser vi et kryssplott av `spordybde` mot `sporing_trafikk`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd73be4-abdb-4afe-be6b-0566c12ab90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['spordybde'], df['sporing_trafikk'], s = 2)\n",
    "plt.ylabel(\"Sporing/AADT\")\n",
    "plt.xlabel(\"Spordybde\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed3522f-b597-4bdc-949a-90d701d24889",
   "metadata": {},
   "source": [
    "Vi skal tilpasse en enkel lineær modell med `sporing_trafikk` som respons og `spordybde` som (eneste) forklaringsvariabel. Som vi har snakket om i undervisningen, består det å utføre en lineær regresjonsanalyse (både enkel og multippel) av følgende steg:\n",
    "\n",
    "1) Bli kjent med dataene ved å se på oppsummeringsmål og ulike typer plott\n",
    "2) Spesifisere en matematisk modell (modellformel)\n",
    "3) Initialisere og tilpasse modellen\n",
    "4) Presentere resultater fra den tilpassede modellen\n",
    "5) Evaluere om modellen passer til dataene\n",
    "\n",
    "Steg 1 har vi nå gjort (i oppgave 1a)). Koden under gjør steg 2, 3 og 4. Studér og kjør den."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd60e35e-2ab2-4d79-8200-57b8d3984c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steg 2: spesifiser matematisk modell\n",
    "formel = 'sporing_trafikk ~ spordybde'\n",
    "\n",
    "# Steg 3: Initaliser og tilpass en enkel lineær regresjonsmodell\n",
    "# først initialisere\n",
    "modell = smf.ols(formel, data = df)\n",
    "# deretter tilpasse\n",
    "resultat = modell.fit()\n",
    "\n",
    "# Steg 4: Presenter resultater fra den tilpassede regresjonsmodellen\n",
    "resultat.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add33cc-1b0c-4439-88ce-7b90fd52fa8f",
   "metadata": {},
   "source": [
    "**Q1b.1)** Skriv ned ligningen for den estimerte regresjonsmodellen og forklar de ulike elementene.\n",
    "\n",
    "**Q1b.2)** Hva er den estimerte verdien til skjæringspunktet (intercept) $\\hat{\\beta}_0$, og hvordan vil du tolke den?\n",
    "\n",
    "**Q1b.3)** Vi ser at for `spordybde` er `coef` lik 0.2665. Hva er formelen som er brukt for å regne ut denne verdien? Hvordan vil du forklare dette tallet til noen som ikke har hørt om lineær regresjon?\n",
    "\n",
    "**Q1b.4)** For `spordybde` har vi også tallene 0.239 og 0.294 i kolonnene `[0.025 0.975]`. Hva er disse to tallene og hvordan tolker du dem?\n",
    "\n",
    "**Q1b.5)** Videre står det for `spordybde` at `P>|t|` er 0.000. Hvilken hypotese er testet her? Hva er konklusjonen fra hypotesetesten hvis vi bruker signifikansnivå $0.05$? Hvordan henger dette sammen med tallene 0.239 og 0.294 fra forrige punkt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f0a51-8273-4438-a436-f6c9a650d753",
   "metadata": {},
   "source": [
    "Steg 5 gjenstår, og der skal vi evaluere om vi har en god modell, noe vi allerede delvis har gjort. Nå skal vi sjekke modellantagelsene i en enkel lineær regresjon, og det kan vi gjøre ved å lage residual-plott. Men først:\n",
    "\n",
    "\n",
    "**Q1b.6)** Hvilke modellantagelser gjør vi i en enkel lineær regresjon?\n",
    "\n",
    "**Q1b.7)** Hva er en predikert verdi og hva er et residual? Skriv også ned relevante formler.\n",
    "\n",
    "**Q1b.8)** Hvordan kan vi bruke predikert verdi og residual til å sjekke modellantagelsene?\n",
    "\n",
    "**Q1b.9)** Vi får oppgitt tallet `R-Squared` til å være 0.098 (skrives ofte som 9.8%). $R^2$ har i enkel lineær regresjon en sammenheng med korrelasjonskoeffisienten, men det er også en annen definisjon som er relatert til sum av kvadrerte residualer. Hvilken formel er det? Forklar alle symboler. Hvordan vil du forklare $R^2$ til noen som ikke har hørt om enkel lineær regresjon?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba4586-a1a1-4268-867d-b727e20f2343",
   "metadata": {},
   "source": [
    "Vi har i undervisningen snakket om at det er to typer plott vi skal lage med utgangspunkt i residualene, og disse er kodet under."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c053c42-97c8-4cbd-beb4-4c47b402845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steg 5: Evaluere om modellen passer til dataene\n",
    "# Plotte predikert verdi mot residual\n",
    "figure, axis = plt.subplots(1, 2, figsize = (15, 5))\n",
    "sns.scatterplot(resultat.fittedvalues, resultat.resid, ax = axis[0])\n",
    "axis[0].set_ylabel(\"Residual\")\n",
    "axis[0].set_xlabel(\"Predikert verdi\")\n",
    "\n",
    "# Lage kvantil-kvantil-plott for residualene\n",
    "sm.qqplot(resultat.resid, line = '45', fit = True, ax = axis[1])\n",
    "axis[1].set_ylabel(\"Kvantiler i residualene\")\n",
    "axis[1].set_xlabel(\"Kvantiler i normalfordelingen\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e95b8db-24f2-4ff9-b283-369e8797cb94",
   "metadata": {},
   "source": [
    "**Q1b.10)** Studer plottet av predikert verdi mot residual. Hvordan skal et slikt plott se ut hvis modellantagelsene er oppfylt? Hvordan vil du evaluere plottet?\n",
    "\n",
    "**Q1b.11)** Studer QQ-plottet av residualene. Hvordan vil du evaluere plottet?\n",
    "\n",
    "**Q1b.12)** Vil du konkludere med at modellen passer godt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6665aac6-56ab-471f-8489-2f432c7db3d7",
   "metadata": {},
   "source": [
    "### Oppgave 1c) Multippel lineær regresjon<a name=\"oppgave1c\"></a>\n",
    "\n",
    "*Oppgave 1c) inneholder 11 spørsmål som du skal svare på.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08131a89-9561-4e20-81f5-822807246215",
   "metadata": {},
   "source": [
    "I praksis har vi ofte flere prediktorer for sporing (f.eks. veibredde, asfalttype, værforhold, grøftedybde, etc.) og ikke bare spordybden året før. Vi skal se på om det er lurt å ta med mer enn bare spordybde i modellen vår.\n",
    "\n",
    "En rekke plott vises under. Vi ser kryssplott, tetthetsplott (en glattet versjon av histogram), og boksplott. For tetthetsplottene og boksplottene ser vi også at vi deler data inn i `asfalttype` for å se om `asfalttype` påvirker effekten som `spordybde` og `veibredde` har på `sporing_trafikk`.\n",
    "\n",
    "(Husk fra 1a): A1 = skjelettasfalt, A2 = asfaltbetong, A3 = asfaltgrusbetong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55035516-61e3-44f5-9c5d-143eda3d1ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kryssplott av spordybde mot sporing_trafikk, veibredde mot sporing_trafikk, og spordybde mot veibredde.\n",
    "# På diagonalen er glattede histogrammer (tetthetsplott) av sporing_trafikk, spordybde og veibredde\n",
    "sns.pairplot(df, vars = ['sporing_trafikk', 'spordybde', 'veibredde'],\n",
    "             diag_kind = 'kde',\n",
    "             plot_kws = dict(alpha = 0.4))\n",
    "plt.show()\n",
    "\n",
    "# Boksplott av sporing_trafikk mot asfalt\n",
    "ax = sns.boxplot(x = \"asfalt\", y = \"sporing_trafikk\", data = df)\n",
    "plt.show()\n",
    "\n",
    "# Kryssplott av spordybde mot sporing_trafikk, nå med farger for asfalttype\n",
    "sns.pairplot(df, vars = ['sporing_trafikk', 'spordybde', 'veibredde'],\n",
    "             hue = 'asfalt', \n",
    "             diag_kind = 'kde',\n",
    "             plot_kws = dict(alpha = 0.4))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7850d9-886e-4880-b847-1d5e83c8f865",
   "metadata": {},
   "source": [
    "**Q1c.1)** Oppsummer kort hva du ser i plottene. Fokus skal være om du tror at det er noen sammenheng mellom `sporing_trafikk` (som respons) og de tre forklaringsvariablene (`spordybde`, `veibredde` og `asfalt`). Hvilken asflattype har høyest verdi for sporing_trafikk?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e30f789-4df4-4f80-8119-b7fb3a47a1a3",
   "metadata": {},
   "source": [
    "Vi skal nå tilpasse en multippel lineær regresjon med `sporing_trafikk` som respons, og `spordybde`, `veibredde` og `asfalt` som forklaringsvariabler. Den nye modellformelen blir da:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83b1d9-fea1-45c8-8585-79de284e682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "formel = 'sporing_trafikk ~ spordybde + veibredde + asfalt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdc8a2d-272a-441d-9931-7268c53492c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# her kan du lime inn koden for å tilpasse den nye modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21a7a72-9f3e-45cd-bae1-7d775961dd39",
   "metadata": {},
   "source": [
    "**Q1c.2)** Tilpass modellen ved å bruke koden for steg 3 og 4 over, med den nye formelen. Skriv ned ligningen for den estimerte regresjonsmodellen.\n",
    "\n",
    "**Q1c.3)** Hvor mange regresjonsparametere er estimert? Hva er betydningen av de ulike regresjonsparameterene?\n",
    "\n",
    "**Q1c.4)** Sammenlign den estimerte regresjonskoeffisienten for `spordybde` i denne modellen med samme koeffisient i den enkle lineære regresjonsmodellen. Har disse to samme tolkning?\n",
    "\n",
    "**Q1c.5)** Hva er predikert sporing per ti tusen biler for en veistrekning med asfaltbetong, 10 mm spordybde og 4 meter veibredde? (Regn ut for hånd ved å bruke relevante tall fra `resultat.summary()`.)\n",
    "\n",
    "**Q1c.6)** Forklaringsvariabelen `asfalt` er kategorisk og vi har brukt en såkalt dummy-variabelkoding, der `A1` (skjelettasfalt) er referansekategorien. Er effekten av de andre asfalttypene på sporing per ti tusen biler signifikant forskjellig fra effekten for asfaltbetong på nivå $0.05$? Hvis vi sammenligner tre deler av veien med lik spordybde og veibredde, men ulik asfalttype, hva er gjennomsnittlig forskjell i sporing per ti tusen biler? Hvilken type asfalt ser ut til å gi den mest solide veien?\n",
    "\n",
    "**Q1c.7)** Hva er andel forklart variasjon? Ville du forventet at andelen forklart variasjon gikk opp da vi la til flere forklaringsvariabler enn bare `spordybde`? Hvis vi nå la til en forklaringsvariabel som beskriver fargen på bilene som kjører på veien, ville da $R^2$ økt?\n",
    "\n",
    "**Q1c.8)** Basert på utskrifter og plott, vil du konkludere med at modelltilpasningen er god?\n",
    "\n",
    "Helt til slutt lurer vi på om vi kan kutte ut asfalttype i modellen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c3b7e3-3594-4246-8212-b975f396f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# her kan du lime inn koden for å tilpasse den nye modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0038501-ba9e-46cc-9393-c0b2bca79bd1",
   "metadata": {},
   "source": [
    "**Q1c.9)** Utfør en ny multippel lineær regresjon (steg 2-5) med `sporing_trafikk` som respons og `veibredde` og `spordybde` som forklaringsvariabler. Du må nå modifisere modellformelen ved å ta bort `asfalt`, og så kopiere inn kode for steg 2-5. Hvor mange regresjonsparametere er nå estimert? Hva er de signifikante forklaringsvariablene?\n",
    "\n",
    "**Q1c.10)** Er modelltilpasningen god?\n",
    "\n",
    "**Q1c.11)** Sammenlign `Adj. R-squared` (også kalt justert $R^2$) for modellen med og uten `asfalt`. Hvis vi skal avgjøre om `asfalt` skal være med som forklaringsvariabel ved å bruke justert $R^2$, hva blir konklusjonen? Begrunn svaret ditt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50680e03-6b7d-4292-8462-0074c366736e",
   "metadata": {},
   "source": [
    "[Til toppen.](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f53ccfb-fa2a-4a9b-9867-0ba9ed711e0f",
   "metadata": {},
   "source": [
    "# Oppgave 2 - Klassifikasjon (30%)<a name=\"oppgave2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4491adb-207f-4baf-bc9c-9b02f7bffc7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "*Oppgave 2 inneholder 4 deler med oppgaver, og alle 13 spørsmål (Q2a.1), Q2a.2) etc.) teller likt. Oppgave 2 teller totalt 30 % av prosjektet.*\n",
    "\n",
    "**Oppgaven inneholder følgende elementer:**\n",
    "\n",
    "* Laste inn og utforske et datasett for klassifikasjon\n",
    "* Dele datasettet inn i treningssett, valideringssett og testsett\n",
    "* Tilpasse en logistisk regresjon og diskutere denne\n",
    "* Utføre $k$-nærmeste nabo-klassifikasjon, og evaluere godhet av klassifikasjonsresultatene\n",
    "\n",
    "## Innholdsfortegnelse\n",
    "* [Ble det hjemmeseier?](#intro)\n",
    "* [Oppgave 2a) Lese inn og preprosessere data](#oppgave2a)\n",
    "* [Oppgave 2b) Logistisk regresjon](#oppgave2b)\n",
    "* [Oppgave 2c) $k$-nærmeste-nabo-klassifikasjon](#oppgave2c)\n",
    "* [Oppgave 2d) Evaluere beste modeller](#oppgave2d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b64617-f341-4446-92fb-c35c281226b8",
   "metadata": {},
   "source": [
    "### Ble det hjemmeseier?<a name=\"intro\"></a>\n",
    "\n",
    "Datasettet vi skal se på er fra de fire øverste divisjonene i engelsk fotball, i sesongen  2021-2022 og oppgaven går ut på å tilpasse ulike metoder for å predikere om hjemmelaget vinner en gitt kamp utifra data på antall skudd på mål, cornere og forseelser (regelbrudd som fører til frispark eller straffespark).\n",
    "\n",
    "Mer informasjon om dataene: https://www.football-data.co.uk/englandm.php."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04c446-b014-430a-8a24-2076ae6c4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importere pakker og funksjoner vi trenger i oppgave 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# fordelinger, modeller for regresjon, qq-plott \n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# trening og testsett, evaluering av klassifikasjonsmetoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5adecc-0262-498c-ac0d-b3da5eb2b1f3",
   "metadata": {},
   "source": [
    "### Oppgave 2a) Lese inn og preprosessere data<a name=\"oppgave2a\"></a>\n",
    "\n",
    "*Oppgave 2a) inneholder 5 spørsmål du skal svare på.*\n",
    "\n",
    "I datasettet vi skal jobbe med inneholder hver rad i datasettet informasjon om en kamp, der to lag møtte hverandre. Dataene finnes i fire forskjellige filer, og hver fil inneholder informasjon om kampene i en gitt divisjon. Vi laster inn dataene fra hver fil og kombinerer dem. Etter vi har gjort dette har datasettet $2026$ rader og $106$ kolonner. En gitt rad tilsvarer en gitt kamp og en gitt kolonne tilsvarer en type informasjon (f.eks. antall cornere hjemmelaget hadde). Kolonner som begynner på `H` angår hjemmelaget og `A` angår bortelaget.\n",
    "\n",
    "I en gitt kamp vinner enten hjemmelaget, eller så vinner ikke hjemmelaget (uavgjort eller borteseier). Resultatet av en kamp er dermed at:\n",
    "* hjemmelaget vinner - kodet som $1$\n",
    "* hjemmelaget vinner ikke - kodet som $0$.\n",
    "\n",
    "Kampresultatet ($0$ eller $1$) legger vi i kolonnen `y`, som skal være hva vi vil predikere.\n",
    "\n",
    "Vi skal ikke se på alle variablene i datasettet, og skal i tillegg til `y` konsentrere oss om\n",
    "\n",
    "* `HST`, `AST`: antall skudd på mål for henholdsvis hjemmelaget og bortelaget\n",
    "* `HC`, `AC`: antall cornere for henholdsvis hjemmelaget og bortelaget\n",
    "* `HF`, `AF`: antall forseelser for henholdsvis hjemmelaget og bortelaget\n",
    "\n",
    "Istedenfor å se direkte på disse tre antallene for de to lagene, skal vi for hver kamp lage\n",
    "\n",
    "* `skudd_paa_maal_diff`=`HST`-`AST`\n",
    "* `corner_diff`=`HC`-`AC`\n",
    "* `forseelse_diff`=`HF`-`AF`\n",
    "\n",
    "og dette skal være våre eneste forklaringsvariabler for hver kamp.\n",
    "\n",
    "_Oppsummert_: Observasjonsenheten i dataene er en fotballkamp, vi har tre forklaringsvariabler `skudd_paa_maal_diff`, `corner_diff` og `forseelse_diff`, og `y` (0 eller 1) er responsen vi ønsker å predikere.\n",
    "\n",
    "\n",
    "Koden under leser inn dataene, lager de nye variablene og putter alt inn i en ny data frame. Etter det er gjort har vi en datasett med $2026$ rader (kamper) og $4$ kolonner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9bea7a-d0fe-4fe5-9239-253531848651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lese inn datasettene ved funksjon fra pandas (df=data frame - vanlig navn å gi et datasett)\n",
    "df0 = pd.read_csv(\"https://www.math.ntnu.no/emner/IST100x/ISTx1003/h2022/E0.csv\", sep = ',') # Premier League\n",
    "df1 = pd.read_csv(\"https://www.math.ntnu.no/emner/IST100x/ISTx1003/h2022/E1.csv\", sep = ',') # Championship\n",
    "df2 = pd.read_csv(\"https://www.math.ntnu.no/emner/IST100x/ISTx1003/h2022/E2.csv\", sep = ',') # League 1\n",
    "df3 = pd.read_csv(\"https://www.math.ntnu.no/emner/IST100x/ISTx1003/h2022/E3.csv\", sep = ',') # League 2\n",
    "\n",
    "# Sett sammen datasettene til 1 data-frame\n",
    "df_in=pd.concat([df0,\n",
    "                 df1,\n",
    "                 df2,\n",
    "                 df3], ignore_index = True)\n",
    "df=pd.concat([pd.Series(np.where(df_in['FTR'] == 'H', 1, 0)),\n",
    "              df_in['HST']-df_in['AST'], \n",
    "              df_in['HC']-df_in['AC'],\n",
    "              df_in['HF']-df_in['AF']], axis = 1)\n",
    "\n",
    "# Henter ut de dataene vi er interessert i\n",
    "df.columns=['y', 'skudd_paa_maal_diff', 'corner_diff', 'forseelse_diff']\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb17188-ab93-4813-9ea7-f4d4547fea41",
   "metadata": {},
   "source": [
    "\n",
    "Videre vil vi dele datasettet vårt inn i tre datasett: et treningssett, et valideringssett og et testsett. Først deler vi data inn i 80\\% trening/validering og 20\\% test, og deretter deler vi trening/valideringssettet inn i 75\\% trening og 25\\% validering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895976ee-ad00-4635-9b74-7c159f585171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trenval, df_test = train_test_split(df, test_size = 0.2, random_state = 1000, stratify = df['y'])\n",
    "df_tren, df_val = train_test_split(df_trenval, test_size = 0.25, random_state = 1, stratify = df_trenval['y'])\n",
    "print(\"tren: \", df_tren.shape)\n",
    "print(df_tren.describe())\n",
    "print(\"val: \", df_val.shape)\n",
    "print(df_val.describe())\n",
    "print(\"test: \", df_test.shape)\n",
    "print(df_test.describe())\n",
    "print(df_tren[\"y\"].value_counts())\n",
    "print(df_val[\"y\"].value_counts())\n",
    "print(df_test[\"y\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32821a4f-9a0b-41f7-bda1-1f81725af11a",
   "metadata": {},
   "source": [
    "I denne oppgaven skal vi etterhvert tilpasse logistisk regresjon og $k$-nærmeste nabo-klassifikasjon.\n",
    "\n",
    "**Q2a.1)** Hvorfor ønsker vi å dele dataene inn i trening-, validering- og test-sett?\n",
    "\n",
    "**Q2a.2)** Hva brukes hver av disse delene til i våre analyser?\n",
    "\n",
    "**Q2a.3)** Hvor stor andel av dataene er nå i hver av de tre settene? Ser de tre datasettene ut til å ha lik fordeling for de tre forklaringsvariablene og responsen?\n",
    "\n",
    "For å utforske dataene lager vi kryssplott av de tre forklaringsvariablene for treningsdataene og fargelegger punktene fra kampene etter hvorvidt det var hjemmeseier eller ikke. På diagonalen ser vi empiriske tetthetsplott (glattet variant av et histogram). Vi har også regnet ut empirisk korrelasjonskoeffisient for alle par av variabler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb920a-700d-4d69-8193-9c803d6f1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_tren, vars = ['skudd_paa_maal_diff','corner_diff','forseelse_diff'],\n",
    "             hue = 'y', \n",
    "             diag_kind = 'kde',\n",
    "             plot_kws = dict(alpha = 0.4))\n",
    "plt.show()\n",
    "\n",
    "corr = df_tren.corr()\n",
    "display(corr.style.background_gradient(cmap = 'coolwarm', axis = None, vmin = -1, vmax = 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dd2ccb-8b52-4f00-8ec3-16c86061019f",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Q2a.4)** Kommenter hva du ser i plottene og utskriften.\n",
    "\n",
    "**Q2a.5)** Hvilke av de tre variablene tror du vil være gode til å bruke til å predikere om det blir hjemmeseier? Begrunn svaret kort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0af9427-1af5-461a-a24d-38b0529d3abd",
   "metadata": {},
   "source": [
    "### Oppgave 2b) Logistisk regresjon<a name=\"oppgave2b\"></a>\n",
    "\n",
    "*Oppgave 2b) inneholder 5 spørsmål du skal svare på.*\n",
    "\n",
    "Vi tilpasser en logistisk regresjon til treningssettet, og regner ut feilrate for valideringssettet gitt at vi klassifiserer som suksess (hjemmeseier) når sannsynligheten for hjemmeseier er anslått til minst 0.5.\n",
    "\n",
    "Dette gjør vi med de samme stegene som det vi gjorde for multippel lineær regresjon:\n",
    "\n",
    "1) Bli kjent med dataene ved å se på oppsummeringsmål og ulike typer plott\n",
    "2) Spesifisere en matematisk modell (modellformel)\n",
    "3) Initialisere og tilpasse modellen\n",
    "4) Presentere resultater fra den tilpassede modellen\n",
    "5) Evaluere om modellen passer til dataene\n",
    "\n",
    "Vi er ferdige med Steg 1, og gjør så Steg 2-4 under."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6777840-763d-47fd-9005-0ab7847b247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steg 2: Modellformel\n",
    "formel = \"y ~ skudd_paa_maal_diff + corner_diff + forseelse_diff\"\n",
    "\n",
    "# Steg 3: Initialiser modellen \n",
    "modell = smf.logit(formel, data = df_tren)\n",
    "\n",
    "# Tilpass modellen\n",
    "resultat = modell.fit()\n",
    "\n",
    "# Steg 4: Presenter resultater fra den tilpassede modellen \n",
    "print(resultat.summary())\n",
    "\n",
    "# Tolkning av estimerte regresjonsparametere er på exp-skala (odds)\n",
    "print(\"FLERE utregninger:\")\n",
    "print(\"exp(beta): \\n\", np.exp(resultat.params), sep = \"\")\n",
    "\n",
    "# Spesifiser verdi for cutoff\n",
    "cutoff = 0.5\n",
    "\n",
    "# Prediker verdi for valideringssettet\n",
    "val_pred = resultat.predict(exog = df_val)\n",
    "\n",
    "# Klassifiser som seier for hjemmelaget hvis sannsynligheten for at hjemmelaget vant er over 0.5\n",
    "y_valpred = np.where(val_pred > cutoff, 1, 0)\n",
    "y_valobs = df_val['y']\n",
    "\n",
    "# Finn andel ukorrekte klassifikasjoner\n",
    "print(\"Feilrate:\", 1 - accuracy_score(y_true = y_valobs, y_pred = y_valpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9244beb-e72f-4f83-a4e4-04c627d36e31",
   "metadata": {},
   "source": [
    "**Q2b.1)** Hvilke forklaringsvariabler er signifikante i modellen på signifikansnivå $0.05$?\n",
    "\n",
    "**Q2b.2)** Hvordan kan du tolke verdien av `exp(skudd_paa_maal_diff)`?\n",
    "\n",
    "**Q2b.3)** Hva angir feilraten til modellen? Hvilket datasett er feilraten regnet ut fra? Er du fornøyd med verdien til feilraten?\n",
    "\n",
    "Tilpass nå den logistiske regresjonen uten `exp(forseelse_diff)` som forklaringsvariabel - ved å kopiere koden over (men ikke den gamle formelen).\n",
    "\n",
    "**Q2b.4)** Diskuter hva du ser.\n",
    "\n",
    "**Q2b.5)** Som din beste modell for logistisk regresjon, vil du velge modellen med eller uten `forseelse_diff` som kovariat? Begrunn svaret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e715d-a5ee-46c6-8205-d1fb77df6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steg 2: Modellformel\n",
    "formel2 = \"y ~ skudd_paa_maal_diff + corner_diff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0b5bdb-8812-4f1d-937d-1b258a52e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# her kan du lime inn Steg 3-4 fra koden over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce67f6-f9a2-4c77-ac33-9485a95729e6",
   "metadata": {},
   "source": [
    "### Oppgave 2c) $k$-nærmeste-nabo-klassifikasjon<a name=\"oppgave2c\"></a>\n",
    "\n",
    "*Oppgave 2c) inneholder 1 spørsmål du skal svare på.*\n",
    "\n",
    "Vi skal nå kun se på forklaringsvariablene `skudd_paa_maal_diff` og `corner_diff`, og tilpasse $k$-nærmeste-nabo-metoden der vi bruker euklidsk avstand som avstandsmål. Vi bruker valideringssettet til å velge $k$.\n",
    "\n",
    "Koden under tilpasser $k$-nærmeste nabo-klassifikasjon for ulike verdier for $k$, deretter regnes feilrate ut på valideringssettet og plottes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831f1df-edf6-4085-9156-bc2f4218da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "knaboer = np.arange(1, 49, step = 2)\n",
    "val_feilrate = np.empty(len(knaboer))\n",
    "\n",
    "X_tren = df_tren[['skudd_paa_maal_diff', 'corner_diff']] # bruker bare disse to forklaringsvariablene\n",
    "X_val = df_val[['skudd_paa_maal_diff', 'corner_diff']] \n",
    "\n",
    "for i,k in enumerate(knaboer):\n",
    "    \n",
    "#Initialiser kNN med  k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors = k, p = 2) # p = 2 gir euklidsk avstand\n",
    "\n",
    "# Tilpass modellen med treningssettet\n",
    "    knn.fit(X_tren, df_tren['y'])\n",
    "    \n",
    "# Beregn feilrate på valideringssett\n",
    "# score er accuracy= \"andel korrekt\"\n",
    "    val_feilrate[i] = 1 - knn.score(X_val, df_val['y'])\n",
    "    \n",
    "# Lage plott\n",
    "plt.title('k-NN for ulike verdier av antall naboer k')\n",
    "plt.plot(knaboer, val_feilrate, label = 'Feilrate på valideringssettet')\n",
    "plt.legend()\n",
    "plt.xlabel('Antall naboer k')\n",
    "plt.ylabel('Feilrate')\n",
    "plt.show()\n",
    "\n",
    "valres=np.vstack((knaboer, val_feilrate))\n",
    "print(\"Valideringsfeilrate:\")\n",
    "print(valres.T)\n",
    "\n",
    "mink_valfeilrate = knaboer[np.where(val_feilrate == val_feilrate.min())]\n",
    "print(mink_valfeilrate[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b5940-8fb0-4131-a57f-a02e7a800d46",
   "metadata": {},
   "source": [
    "**Q2c.1)** Forklar kort hva som er gjort i koden over, og hvilken verdi av $k$ du vil velge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f018fcc-f129-4e6f-b35d-2ddb46a0133d",
   "metadata": {},
   "source": [
    "### Oppgave 2d) Evaluere beste modeller<a name=\"oppgave2d\"></a>\n",
    "\n",
    "*Oppgave 2d) inneholder 2 spørsmål du skal svare på.*\n",
    "\n",
    "Nå tar vi frem testsettet og sammenligner den beste modellen for logistisk regresjon med den beste for $k$-nærmeste-nabo-klassifikasjon.\n",
    "\n",
    "**Gjør nødvendige endringer i koden under.**\n",
    "\n",
    "**Q2d.1)** Vil du foretrekke å bruke logistisk regresjon eller $k$-nærmeste-nabo-klassifikasjon på fotballkampdataene?\n",
    "\n",
    "**Q2d.2)** Oppsummer hva du har lært at kan være en god metode for å predikere om hjemmelaget vinner en fotballkamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f470f41-d253-4d30-9d29-23d24732de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beste resultat for logistisk regresjon\n",
    "bestelogist = 0 # hva er navnet på resultatobjektet fra den logistiske regresjon du valgte? var det den med eller uten forseelse_diff?\n",
    "test_pred = bestelogist.predict(exog = df_test)\n",
    "y_testpred = np.where(test_pred > cutoff, 1, 0)\n",
    "y_testobs = df_test['y']\n",
    "print(\"Feilrate logistisk regresjon:\", 1 - accuracy_score(y_true = y_testobs, y_pred = y_testpred))\n",
    "\n",
    "# beste resultat for kNN\n",
    "bestek = 0 # hva er din beste k?\n",
    "knn = KNeighborsClassifier(n_neighbors = bestek, p = 2)\n",
    "knn.fit(X_tren, df_tren['y'])\n",
    "X_test=df_test[['skudd_paa_maal_diff', 'corner_diff']]\n",
    "print(\"Feilrate kNN:\", 1 - knn.score(X_test, df_test['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec3f7f0-f9d3-4f92-ad85-00439b22c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS - plotting av klassegrensene for de beste modellene!\n",
    "\n",
    "X = X_tren\n",
    "n = 50  # steglengde\n",
    "# lage et grid for å plotte\n",
    "x_min, x_max = X['skudd_paa_maal_diff'].min() - 0.5, X['skudd_paa_maal_diff'].max() + 0.5\n",
    "y_min, y_max = X['corner_diff'].min() - 0.5, X['corner_diff'].max() + 0.5\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, n),\n",
    "                     np.linspace(y_min, y_max, n))\n",
    "# Plotter nå klassegrensen, ved å predikere klassen til hver observasjon i griddet vi laget.\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    " \n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "ax.contour(xx, yy, Z, cmap = plt.cm.Paired)\n",
    "ax.scatter(xx, yy, c = Z, marker = \".\",cmap = plt.cm.coolwarm)\n",
    "ax.set_xlabel('skudd_paa_maal_diff', fontsize = 18)\n",
    "ax.set_ylabel('corner_diff', fontsize = 18)\n",
    "#fig.show()\n",
    "\n",
    "# legger til klassegrensen for logistisk regresjon - dette blir bare riktig hvis du \n",
    "# har valgt modellen med skudd_paa_maal_diff og corner_diff som den beste modellen\n",
    "\n",
    "beta0 = resultat.params[0]\n",
    "beta1 = resultat.params['skudd_paa_maal_diff']\n",
    "beta2 = resultat.params['corner_diff']\n",
    "x = np.linspace(-1.5, 4.5, n)\n",
    "y = -beta0/beta2 - x*beta1/beta2\n",
    "plt.plot(x, y, '-r', label = 'logistisk klassegrense')\n",
    "plt.scatter(X_tren['skudd_paa_maal_diff'], X_tren['corner_diff'], c = df_tren['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c56bc43-64b6-4543-9945-fe6f20e6c45c",
   "metadata": {},
   "source": [
    "[Til toppen.](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b429e8a0-b1f2-446a-932a-f211ec9ecb6e",
   "metadata": {},
   "source": [
    "# Oppgave 3: Klyngeanalyse (20%)<a name=\"oppgave3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9613bf8b-dc3c-46d7-b76b-74e5e16858de",
   "metadata": {},
   "source": [
    "*Oppgave 3 inneholder 4 deler med oppgaver, og alle 11 spørsmål (Q3a.1), Q3a.2) etc.) teller likt. Oppgave 3 teller totalt 20 % av prosjektet.*\n",
    "\n",
    "**Oppgaven inneholder følgende elementer:**\n",
    "\n",
    "* Laste inn og utforske et bilde, gjøre bildet om til et datasett for bruk i klyngeanalyse\n",
    "* Bruk $K$-gjennomsnitt-klyngeanalyse får å finne klynger i bilder av håndskrevne tall. \n",
    "* Vise resultater fra klyngeanalysen - som bilde - og tolke resultatene\n",
    "* Diskutere $K$-gjennomsnitt-klyngeanalyse vs. hierarkisk klynganalyse\n",
    "* Utvide til flere klynger i $K$-gjennomsnitt-klyngeanalyse\n",
    "\n",
    "## Innholdsfortegnelse\n",
    "* [Introduksjon](#intro)\n",
    "* [Oppgave 3a) Les inn datasettet og bli kjent med det](#oppgave3a)\n",
    "* [Oppgave 3b) Klyngeanalyse med $K$-gjennomsnitt](#oppgave3b)\n",
    "* [Oppgave 3c) Hierarkisk klyngeanalyse](#oppgave3c)\n",
    "* [Oppgave 3d) Prediksjon](#oppgave3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7edc382-8cc0-4ded-a554-01a206777d84",
   "metadata": {},
   "source": [
    "### Finn klynger (struktur) i bildene av håndskrevne tall<a name=\"intro\"></a>\n",
    "\n",
    "Et stort felt innom maskinlæring er bildegjenkjenning (image recognition) og klassifisering. Dette betyr at vi vil laste inn et bilde til en statistisk algoritme, og får tilbake en etikett som beskriver hva bildet representerer, for eksempel en person, et tall, en sykdom, osv.\n",
    "\n",
    "I denne oppgaven skal vi jobbe med data fra *mnist* (Modified National Institure of Standards and Technology) databasen, som for eksempel finnes her: https://www.kaggle.com/c/digit-recognizer. Datasettet inneholder digitaliserte bilder av handskrevne siffer (0-9), og dette pleier å bli brukt for å trene maskinlæringalgoritmer for klassifisering (det betyr at du vil forutsi hvilket tall et bestemt bilde inneholder, slik at datamaskinen kan lese tall, for eksempel postnummer på et brev).\n",
    "\n",
    "Her bruker vi dette datasettet til noe annet: Vi vil undersøke om vi finner struktur i bildene ved bruk av en klyngeanalyse. Vi vil jo kanskje håpe at de samme sifrene kommer til å bli gruppert i en klynge fordi de inneholder lignende mønstre. Her skal vi se om det er sant. \n",
    "\n",
    "Vi har lært om to populære algoritmer som brukes til å lage klynger av objekter: \n",
    "\n",
    "   * $K$-gjennomsnitt ($K$-means) algoritmen: Målet med denne algoritmen er å plassere de individuelle observasjonene i $K$ grupper (kalt klynger) basert på observasjonenes avstand til grupper av andre observasjoner. Algoritmen kjøres iterativt, og stoppes når at alle observasjoner som ligner hverandre er plassert i en gruppe (klynge) sammen.\n",
    "   * Hierarkisk klyngeanalyse (se nedenfor).\n",
    "\n",
    "**Vi skal kun se på 3 ulike siffer mellom 0 og 9.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f563e7-2db5-4482-94c8-8828ff5df3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importere pakker og funksjoner vi trenger i oppgave 3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans  # k-gjennomsnitt klyngeanalyse\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a877898-b302-4386-8378-3fed277e695f",
   "metadata": {},
   "source": [
    "### Oppgave 3a) Les inn datasettet og bli kjent med det<a name=\"oppgave3a\"></a>\n",
    "\n",
    "*Oppgave 3a) inneholder 3 spørsmål du skal svare på.*\n",
    "\n",
    "Vi begynner med å lese inn datasettet som inneholder informasjon om digitaliserte handskrevne siffer. Hvert siffer finnes i en firkant med $28\\cdot 28$ = 784 pixler, og dermed er hvert bilde representert som en vektor med lengde 784.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e5d57-9597-419d-b367-140c8410513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leser inn datasettet og ser på de første 5 radene (tallene)\n",
    "\n",
    "images = pd.read_csv('https://www.math.ntnu.no/emner/IST100x/ISTx1003/h2022/mnist2022.csv', sep = \",\", index_col = 0)\n",
    "\n",
    "images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e468a377-a8d3-448a-9b7b-d34fe0b6d2ca",
   "metadata": {},
   "source": [
    "Å skrive ut headeren gir oss lite informasjon. Pikslene for disse bildene er gitt som et tall mellom 0 og 255 (gråskala), hvor 0 representerer helt svart og 255 representerer helt hvitt. Pikslene representert ovenfor er det øverste venstre hjørnet av bildet, og det nedre høyre hjørnet av bildet, som vi forventer ville være tomt (svart, og derfor 0).\n",
    "\n",
    "Vi ønsker å standardisere disse tallene slik at de er mellom 0.0 og 1.0 før analysen utføres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c603b039-08fd-4be1-9d77-98e037a0af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## standardisering av dataene\n",
    "images = images/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52edf73-9c9d-441c-8fb3-85e8975e1265",
   "metadata": {},
   "source": [
    "Vi vil vite litt om formatet til datasettet vårt, og skriver ut litt informasjon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036d475-16ba-4d52-9d34-f908c08114c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bildet har type\", type(images))\n",
    "print(\"Størrelsen til tabellen er\", images.shape)\n",
    "# gjennomsnittfargen i bilde 50 (MERK: vi ber om bildet på plass 49, siden det første bildet er på plass 0)\n",
    "print(\"Gjennomsnittsfarge i bilde 50 er\", images.iloc[49].mean())\n",
    "print('Dataformatet til en piksel er', type(images.iloc[1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7bbea6-bd90-4209-b17b-68ab37ec6b53",
   "metadata": {},
   "source": [
    "Nå skal vi se på de første 10 tallene i datasettet vårt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569c4a3-19f3-4eef-ae64-1a09d2ac665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(images)\n",
    "features = features.reshape(features.shape[0], 28,28)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "for i in range(10):\n",
    "    fig.add_subplot(1, 10, i+1)\n",
    "    plt.imshow(features[i], cmap = 'gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f33a2-073d-4f28-b61f-ba203800b5e3",
   "metadata": {},
   "source": [
    "Det er ganske enkelt for oss mennesker å gjenkjenne disse individuelle sifferene -- selv om håndskrift kan være ganske uleselig. Nå vil vi se hvor bra $K$-gjennomsnittsalgoritmen finner struktur i disse dataene."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a66ba-060f-460c-95d9-09ab4b682c93",
   "metadata": {},
   "source": [
    "**Q3a.1)** Hvilke 3 siffer har vi i datasettet? (Alle 3 sifrene er representert blant de første 10)\n",
    "\n",
    "**Q3a.2)** Hvor mange bilder har vi i datasettet?  \n",
    "\n",
    "**Q3a.3)** Hvilket siffer ligner det 500. bildet i datasettet vårt på? Lag et bilde som viser dette sifferet. (Husk at Python begynner nummereringen med 0, og derfor refereres det 500. bildet til `[499]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7ee029-7c0a-4616-993d-6678d14f9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# her kan du lime inn og redigere kode for å plotte bildet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc4e70a-f2e0-4d56-bb29-9040e47e65b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Oppgave 3b) Klyngeanalyse med $K$-gjennomsnitt<a name=\"oppgave3b\"></a>\n",
    "\n",
    "*Oppgave 3b) inneholder 4 spørsmål du skal svare på.*\n",
    "\n",
    "La oss nå utføre $K$-gjennomsnittalgoritme. Vi må gå gjennom følgende steg:\n",
    "\n",
    "  1. Angi antall klynger du ønsker\n",
    "  2. Initialiser $K$-gjennomsnitt-modellen\n",
    "  3. Tilpass $K$-gjennomsnitt-modellen\n",
    "\n",
    "Vi bruker $K$-gjennomsnittsfunksjonen med $K=3$ (se kode under), fordi vi håper jo å finne igjen de 3 sifferene i klyngene.\n",
    "\n",
    "I tillegg kan vi få tilgang til sentroidene i klyngene våre i tabellen `means.cluster_centers_`, og plotte dem for å se hvordan algoritmen mener de typiske bildene i de $K$ gruppene ser ut.\n",
    "\n",
    "Hint: Her kan du lese litt mer om KMeans-funksjonen: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e4b5a-380d-42af-9606-62f6003ac701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steg 1: Antall klynger\n",
    "antall_klynger = 3\n",
    "\n",
    "# Steg 2: Initaliser k-means algoritmen\n",
    "kmeans = KMeans(n_clusters = antall_klynger, random_state = 1)\n",
    "\n",
    "# Steg 3: Tilpass modellen\n",
    "kmeans.fit(images)\n",
    "\n",
    "# sentroidene\n",
    "sentroider = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14fbd8-2262-494a-8615-bda2a5374816",
   "metadata": {},
   "source": [
    "**Q3b.1)** Tegn sentroidene av de 3 klyngene fra $K$-gjennomsnitt modellen. Tilpass koden over for å plotte. Her kan du ta skjermbilde av sentroidene og lime inn i svararket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7593bf6-1b24-43d4-bef7-09b0c128426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# her kan du skrive koden for å plotte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3bc4a5-1f10-461c-928b-9731a7604d39",
   "metadata": {},
   "source": [
    "**Q3b.2)** Synes du at grupperingen i klynger er relevant og nyttig? Forklar. Maks 3 setninger. \n",
    "\n",
    "**Q3b.3)** Vi har valgt $K = 3$ for dette eksempelet fordi vi vil finne klynger som representerer de 3 sifferene. Men generelt er $K$ vilkårlig. Kom opp med et forslag for hvordan man (generelt, ikke nødvendigvis her) best kan velge $K$. (Se her, for eksempel: https://medium.com/analytics-vidhya/how-to-determine-the-optimal-k-for-k-means-708505d204eb). Beskriv i egne ord med maks 3 setninger.\n",
    "\n",
    "**Q3b.4)** Kjør analysen igjen med $K = 2$ og $K = 4$. Synes du de nye grupperingene er relevante?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0562eb-7075-473e-a026-93452540426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# her kan du kjøre analysen med K = 2 og K = 4 (kopier relevant kode og gjør endringer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bf6744-6d83-487c-a5a4-b79f8db1da86",
   "metadata": {},
   "source": [
    "### Oppgave 3c) Hierarkisk klyngeanalyse<a name=\"oppgave3c\"></a>\n",
    "\n",
    "*Oppgave 3c) inneholder 3 spørsmål du skal svare på.*\n",
    "\n",
    "Vi fortsetter nå med å bruke hierarkisk klyngeanalyse for *mnist*-datasettet med 3 sifre. Vi gjør *Agglomerative Clustering* ved bruk av `sklearn.cluster` pakken. (Agglomerative Clustering er noe vi har lært om i undervisningen, men se også her hvis du har lyst til å vite mer: https://en.wikipedia.org/wiki/Hierarchical_clustering)\n",
    "\n",
    " \n",
    "Fordi hierarkisk gruppering er tregt for store datasett, og særlig for grafiske data, ble et tilfeldig utvalg på 30 bilder valgt fra det originale datasettet for å bruke denne modellen for illustrasjon.\n",
    "\n",
    "\n",
    "**Q3c.1)** Vurder dendrogrammet nedenfor. Synes du at den hierarkiske grupperingsalgoritmen har laget gode/meningfulle grupper av bildene?  \n",
    "\n",
    "**Q3c.2)** I koden under har vi brukt gjeonnomsnittskobling (`method = 'average'`). Hvordan fungerer gjeonnomsnittskobling? Maks 2 setninger.\n",
    "\n",
    "**Q3c.3)** Velg en annen måte enn `method = 'average'` til å koble klyngene sammen (vi har lært om dette i undervisningen, her heter de `single`, `complete` og `centriod`) og lag et nytt dendogram ved å tilpasse koden nedenfor. Kommenter resultatene. Ser det bedre/verre ut?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852005a-6641-42c3-a06e-2564cc3ee3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_image = 30\n",
    "\n",
    "sample = images.sample(n = n_image, random_state = 2)\n",
    "\n",
    "sampleimg = np.array(sample).reshape(sample.shape[0], 28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9031e6e4-7882-4d4a-8d21-ed149b559180",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "ax = plt.subplot()\n",
    "\n",
    "# Bruk gjennomsnittskobling (method='average')\n",
    "link = linkage(y = sample, method = 'average', metric = 'euclidean')\n",
    "\n",
    "dendro = dendrogram(link)\n",
    "\n",
    "dcoord = np.array(dendro[\"dcoord\"])\n",
    "icoord = np.array(dendro[\"icoord\"])\n",
    "leaves = np.array(dendro[\"leaves\"])\n",
    "\n",
    "idx = np.argsort(dcoord[:, 2])\n",
    "\n",
    "dcoord = dcoord[idx, :]\n",
    "icoord = icoord[idx, :]\n",
    "\n",
    "idx = np.argsort(link[:, :2].ravel())\n",
    "label_pos = icoord[:, 1:3].ravel()[idx][:n_image]\n",
    "\n",
    "for i in range(n_image):\n",
    "    imagebox = OffsetImage(sampleimg[i], cmap = 'gray', interpolation = \"bilinear\")\n",
    "    ab = AnnotationBbox(imagebox, (label_pos[i], 0),  box_alignment=(0.5, -0.1), \n",
    "                        bboxprops={\"edgecolor\" : \"none\"})\n",
    "    ax.add_artist(ab)\n",
    "\n",
    "plt.title('Dendrogram for håndskrevne tall')\n",
    "plt.xlabel('Siffer')\n",
    "plt.ylabel('Avstand')\n",
    "plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7747561-d14b-449f-9613-fdde7e80edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# her kan du lage et nytt dendrogram med ny 'method' (kopier koden over)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f029fbfe-ce62-4e00-9813-ac141e31a0ff",
   "metadata": {},
   "source": [
    "### Oppgave 3d) Prediksjon<a name=\"oppgave3d\"></a>\n",
    "\n",
    "*Oppgave 3d) inneholder 1 spørsmål du skal svare på.*\n",
    "\n",
    "**Q3d.1)** Hvis vi skulle brukt en metode for å predikere hvilket siffer fra et håndskrevet tall er, og ikke bare samle dem i klynge, hva ville du brukt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744d30e6-b237-46e6-acb6-19030ebc76ea",
   "metadata": {},
   "source": [
    "[Til toppen.](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
